{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14176544\n"
     ]
    }
   ],
   "source": [
    "'''Example: Pi'''\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import random\n",
    "sc = pyspark.SparkContext(appName=\"Pi\")\n",
    "num_samples = 100000000\n",
    "def inside(p):     \n",
    "  x, y = random.random(), random.random()\n",
    "  return x*x + y*y < 1\n",
    "count = sc.parallelize(range(0, num_samples)).filter(inside).count()\n",
    "pi = 4 * count / num_samples\n",
    "print(pi)\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[6] at RDD at PythonRDD.scala:48\n"
     ]
    }
   ],
   "source": [
    "'''Example: word count'''\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"count\")\n",
    "\n",
    "text_file = sc.textFile(\"/Users/LuQiang/Downloads/predict.txt\")\n",
    "counts = text_file.flatMap(lambda line: line.split(\" \")) \\\n",
    "             .map(lambda word: (word, 1)) \\\n",
    "             .reduceByKey(lambda a, b: a + b)\n",
    "print(counts)\n",
    "# counts.saveAsTextFile(\"/Users/LuQiang/Downloads/predictHDFS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 11),\n",
       " ('APIs', 1),\n",
       " ('provide', 2),\n",
       " ('marital', 1),\n",
       " ('Performance', 1),\n",
       " ('writing', 1),\n",
       " ('past', 2),\n",
       " ('Linux/Unix', 1),\n",
       " ('GPA', 1),\n",
       " ('Hours', 1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.count()\n",
    "counts.first()\n",
    "counts.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 34),\n",
       " ('to', 17),\n",
       " ('', 11),\n",
       " ('of', 11),\n",
       " ('a', 11),\n",
       " ('the', 11),\n",
       " ('in', 10),\n",
       " ('.', 8),\n",
       " ('data', 8),\n",
       " ('NREL', 7)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort counts based on each word's count\n",
    "counts_sorted = counts.sortBy(lambda a: a[1], ascending=False)\n",
    "\n",
    "counts_sorted.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('and', 34), ('to', 17), ('', 11), ('of', 11), ('a', 11), ('the', 11), ('in', 10), ('.', 8), ('data', 8), ('NREL', 7), ('will', 7), ('with', 7), ('The', 6), ('is', 6), ('for', 6), ('energy', 6), ('or', 6), ('as', 5), ('experience', 5), ('programming', 4), ('intern', 4), ('work', 4), ('science', 4), ('an', 4), ('you', 4), ('Experience', 3), ('position', 3), ('Please', 3), ('scientific', 3), ('have', 3), ('applicants', 3), ('including', 3), ('that', 3), ('each', 3), ('on', 3), ('provide', 2), ('past', 2), ('both', 2), ('management', 2), ('new', 2), ('12', 2), ('CO', 2), ('are', 2), ('at', 2), ('using', 2), ('diverse', 2), ('Security', 2), ('systems', 2), ('months', 2), ('include', 2), ('projects', 2), ('status,', 2), ('high', 2), ('some', 2), ('Golden,', 2), ('degree', 2), ('should', 2), ('-', 2), ('not', 2), ('skills', 2), ('programming,', 2), ('full-time', 2), ('Department', 2), ('be', 2), ('well', 2), ('All', 2), ('time', 2), ('efficient', 2), ('analysis', 2), ('from', 2), ('technologies', 2), ('future', 2), ('Internship', 2), ('renewable', 2), ('cluster', 2), ('learn', 2), ('databases', 2), ('APIs', 1), ('marital', 1), ('Performance', 1), ('writing', 1), ('Linux/Unix', 1), ('GPA', 1), ('Hours', 1), ('make', 1), ('program,', 1), ('point', 1), ('statistical', 1), ('cumulative', 1), ('E-Verify.', 1), ('learning', 1), ('modeling,', 1), ('Spark/Hadoop', 1), ('candidates', 1), ('Unix/Linux', 1), ('letter', 1), ('Laboratory', 1), ('equal', 1), ('(Peregrine)', 1), ('student', 1), ('Form', 1), ('©', 1), ('These', 1), ('promotes', 1), ('against', 1), ('D.C.,', 1), ('locations', 1), ('queries.', 1), ('coding', 1), ('Windows.', 1), ('enrolled', 1), ('leader', 1), ('scale.', 1), ('48-node', 1), ('2017', 1), ('Demonstrated', 1), ('Ability', 1), ('Week', 1), ('related', 1), ('open', 1), ('Experience,', 1), ('(optionally,', 1), ('basis', 1), ('Energy’s', 1), ('source', 1), ('Required', 1), ('full', 1), ('believe', 1), ('structures', 1), ('Submission', 1), ('ancestry,', 1), ('Intern', 1), ('color,', 1), ('curiosity,', 1), ('transcripts', 1), ('systems.', 1), ('necessary,', 1), ('domains.', 1), ('machine', 1), ('dedicated', 1), ('considered', 1), ('transportation', 1), ('confirm', 1), ('Position', 1), ('age,', 1), ('Applications', 1), ('other', 1), ('computing,', 1), ('kept', 1), ('Job', 1), ('and/or', 1), ('scripting', 1), ('perceived', 1), ('Golden', 1), ('sexual', 1), ('Note:', 1), ('turbine', 1), ('discrimination', 1), ('Location', 1), ('predictive', 1), ('modeling.', 1), ('National', 1), ('needs', 1), ('veteran', 1), ('techniques', 1), ('performance', 1), ('graduated', 1), ('must', 1), ('frameworks', 1), ('form', 1), ('use', 1), ('object-oriented', 1), ('Preferred', 1), ('duties', 1), ('40', 1), ('Per', 1), ('hours', 1), ('fleet', 1), ('applied', 1), ('(DHS),', 1), ('Posting', 1), ('quickly', 1), ('Summary', 1), ('Administration', 1), ('grade', 1), ('religion,', 1), ('solve', 1), ('Washington', 1), ('knowledge', 1), ('About', 1), ('gearbox', 1), ('parallel', 1), ('validates', 1), ('cannot', 1), ('understand', 1), ('(CSC)', 1), ('data.', 1), ('Minimum', 1), ('(SQL),', 1), ('scripts', 1), ('Policy', 1), ('group', 1), ('authorization.', 1), ('Computing', 1), ('granting', 1), ('analysis.', 1), ('perform', 1), ('staff', 1), ('relevant', 1), ('mission', 1), ('period', 1), ('multiple', 1), ('institution.', 1), ('accessing', 1), ('center', 1), ('United', 1), ('software.', 1), ('(e.g.,', 1), ('Java,', 1), ('development', 1), ('origin,', 1), ('python', 1), ('job', 1), ('Specific', 1), ('scientists', 1), ('graduation.', 1), ('exceed', 1), ('actual', 1), ('(NREL)', 1), ('right', 1), ('primary', 1), ('(undergraduate', 1), ('include:', 1), ('modern', 1), ('model', 1), ('Data', 1), ('datacenter', 1), ('differing', 1), ('how', 1), ('employee’s', 1), ('deployment', 1), ('workers', 1), ('advance', 1), ('any', 1), ('I-9', 1), ('software', 1), ('Must', 1), ('involve', 1), ('veterans.', 1), ('big', 1), ('Full', 1), ('plotting', 1), ('Renewable', 1), ('languages),', 1), ('sustainable.', 1), ('background', 1), ('computational', 1), ('Energy', 1), ('Before', 1), ('practices,', 1), ('year-round', 1), ('(ETL),', 1), ('resume', 1), ('reserved.', 1), ('organization', 1), ('seeking', 1), ('file', 1), ('Round)', 1), ('Workday,', 1), ('prohibits', 1), ('Matlab).', 1), ('national', 1), ('curation,', 1), ('design,', 1), ('employment', 1), ('problems', 1), ('information', 1), ('apply', 1), ('secure', 1), ('Homeland', 1), ('visualization', 1), ('note', 1), ('plot.ly,', 1), ('race,', 1), ('special', 1), ('Us', 1), ('and,', 1), ('States.', 1), ('testing', 1), ('wind', 1), ('economically', 1), ('goals.', 1), ('application.', 1), ('environmentally', 1), ('Guidelines', 1), ('prognostics,', 1), ('(Year', 1), ('opportunity.', 1), ('adapt', 1), ('prior', 1), ('libraries', 1), ('(Fixed', 1), ('familiarity', 1), ('(R,', 1), ('vehicle', 1), ('effort', 1), ('our', 1), ('(HPC)', 1), ('rights', 1), ('ability', 1), ('Skills', 1), ('enrollment.', 1), ('settings.', 1), ('operating', 1), ('Inc.', 1), ('environment', 1), ('smart-building', 1), ('R1956', 1), ('verify', 1), ('selection,', 1), ('nation’s', 1), ('application', 1), ('facilities', 1), ('EEO', 1), ('unlawful', 1), ('addition', 1), ('also', 1), ('order', 1), ('if', 1), ('Education,', 1), ('average.', 1), ('Type', 1), ('does', 1), ('matplotlib).', 1), ('address', 1), ('need', 1), ('Boulder', 1), ('research,', 1), ('qualified.', 1), ('distributed', 1), ('innovation', 1), ('graduate).', 1), ('With', 1), ('engineering,', 1), ('willingness', 1), ('accredited', 1), ('mixture', 1), ('which', 1), ('ingest', 1), ('Term)', 1), ('3.0', 1), ('Optional', 1), ('unofficial', 1), ('existing', 1), ('sex,', 1), ('interview', 1), ('disability,', 1), ('Interested', 1), ('High', 1), ('data,', 1), ('positions.', 1), ('applicant', 1), ('Social', 1), ('building', 1), ('laboratory', 1), ('week)', 1), ('develop', 1), ('languages', 1), ('orientation,', 1), ('Successful', 1), ('environmental', 1), ('disabled', 1), ('principles', 1), ('discriminate', 1), ('Title', 1), ('patterns', 1), ('transfer', 1), ('Qualifications', 1), ('(40', 1), ('submit', 1), ('cover', 1), ('Scientist', 1), ('strong', 1), ('per', 1), ('(SSA)', 1), ('U.S.', 1)]\n"
     ]
    }
   ],
   "source": [
    "out = counts_sorted.collect()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data written to file\n"
     ]
    }
   ],
   "source": [
    "# write counts of words to a csv file.\n",
    "import csv\n",
    "\n",
    "with open(\"output.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(out)\n",
    "    \n",
    "print('data written to file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|       word|count|\n",
      "+-----------+-----+\n",
      "|        and|   34|\n",
      "|         to|   17|\n",
      "|           |   11|\n",
      "|         of|   11|\n",
      "|          a|   11|\n",
      "|        the|   11|\n",
      "|         in|   10|\n",
      "|          .|    8|\n",
      "|       data|    8|\n",
      "|       NREL|    7|\n",
      "|       will|    7|\n",
      "|       with|    7|\n",
      "|        The|    6|\n",
      "|         is|    6|\n",
      "|        for|    6|\n",
      "|     energy|    6|\n",
      "|         or|    6|\n",
      "|         as|    5|\n",
      "| experience|    5|\n",
      "|programming|    4|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+\n",
      "|       word|\n",
      "+-----------+\n",
      "|        and|\n",
      "|         to|\n",
      "|           |\n",
      "|         of|\n",
      "|          a|\n",
      "|        the|\n",
      "|         in|\n",
      "|          .|\n",
      "|       data|\n",
      "|       NREL|\n",
      "|       will|\n",
      "|       with|\n",
      "|        The|\n",
      "|         is|\n",
      "|        for|\n",
      "|     energy|\n",
      "|         or|\n",
      "|         as|\n",
      "| experience|\n",
      "|programming|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Example: dataframe'''\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "textFile = sc.textFile(\"/Users/LuQiang/Dropbox/Courses/big-data/Spark/output.csv\")\n",
    "parts = textFile.map(lambda l: l.split(\",\"))\n",
    "# Each line is converted to a tuple.\n",
    "counts = parts.map(lambda p: (p[0], p[1].strip()))\n",
    "\n",
    "# The schema is encoded in a string.\n",
    "schemaString = \"word count\"\n",
    "\n",
    "fields = [StructField(field_name, StringType(), True) for field_name in schemaString.split()]\n",
    "schema = StructType(fields)\n",
    "\n",
    "# Apply the schema to the RDD.\n",
    "schemaPeople = spark.createDataFrame(counts, schema)\n",
    "schemaPeople.show()\n",
    "\n",
    "# Creates a temporary view using the DataFrame\n",
    "schemaPeople.createOrReplaceTempView(\"people\")\n",
    "\n",
    "# SQL can be run over DataFrames that have been registered as a table.\n",
    "results = spark.sql(\"SELECT word FROM people\")\n",
    "\n",
    "results.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
